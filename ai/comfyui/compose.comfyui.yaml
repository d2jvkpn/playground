services:
  comfyui:
    container_name: comfyui
    image: local/comfyui:cuda12.9-base
    #restart: unless-stopped
    restart: always
    init: true
    shm_size: '32gb' # df -g /dev/shm
    #ipc: host
    deploy:
      resources:
        limits: { cpus: '8.0', memory: 32G }
        reservations:
          devices:
          - driver: nvidia
            count: all
            capabilities: [gpu]
    ulimits: # ulimit -l; ulimit -s; ulimit -a; ulimit -Sn; ulimit -Hn
      memlock: { soft: -1, hard: -1 }
      stack: { soft: 67108864, hard: 67108864 }
      nofile: { soft: 65536, hard: 65536 }
    network_mode: bridge
    ports: ["8036:8188"]
    #healthcheck:
    #  test: ["CMD-SHELL", "curl -sfI http://localhost:8188/system_stats &> /dev/null"]
    #  test: ["CMD", "/opt/bin/healthcheck.sh"] # curl -sfS
    #  interval: 20s
    #  timeout: 1s
    #  retries: 3
    #  start_period: 30s
    environment:
      TZ: Asia/Shanghai
      PYTORCH_CUDA_ALLOC_CONF: expandable_segments:True,max_split_size_mb:128
      #COMFYUI_MANAGER_SKIP_UPDATE: "true"
      #CUDA_MPS_ACTIVE_THREAD_PERCENTAGE: "60"
      #NVIDIA_GPU_MEMORY_LIMIT: 32G
      #COMFYUI_MANAGER_DISABLE_UPDATE_CHECK: "true"
      #COMFYUI_MANAGER_SKIP_LOAD: "true"
      #https_proxy: socks5h://127.0.0.1:1080  # http_proxy, https_proxy, no_proxy
      #CONTAINER_INIT_COMMAND: "mv custom_nodes/ComfyUI-Manager custom_nodes/ComfyUI-Manager.disabled"
    volumes:
    #- ./data/container_init.sh:/opt/container_init.sh
    - ./data:/home/appuser/workspace  # models, custom_nodes, user, input, output, temp
    - ./data/site-packages:/home/appuser/venv/lib/python3.12/site-packages
    command:
    - python3
    - /home/appuser/ComfyUI/main.py
    - --base-directory=./
    - --enable-cors-header
    - --listen=0.0.0.0
    - --port=8188
    #- --disable-manager-ui
    #- --disable-smart-memory
    #- --lowvram
    #- --extra-model-paths-config=./extra_model_paths.yaml
