services:
  comfyui:
    container_name: comfyui
    image: local/comfyui:cuda12.9-base
    #restart: unless-stopped
    restart: always
    init: true
    shm_size: '32gb'
    #ipc: host
    deploy:
      resources:
        limits: { cpus: '8.0', memory: 32G }
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    network_mode: bridge
    ports: ["127.0.0.1:8188:8188"]
    #healthcheck:
    #  test: ["CMD-SHELL", "curl -sfI http://localhost:8188/system_stats &> /dev/null"]
    #  test: ["CMD", "/opt/bin/healthcheck.sh"] # curl -sfS
    #  interval: 20s
    #  timeout: 1s
    #  retries: 3
    #  start_period: 30s
    environment:
      TZ: Asia/Shanghai
      #all_proxy: ${PROXY_ADDR} # http_proxy, https_proxy
      #CUDA_MPS_ACTIVE_THREAD_PERCENTAGE: "60"
      #NVIDIA_GPU_MEMORY_LIMIT: 32G
      #CUDA_HOME: ??
      #LD_LIBRARY_PATH: $CUDA_HOME/lib:$LD_LIBRARY_PATH
      #COMFYUI_MANAGER_DISABLE_UPDATE_CHECK: "true"
      #COMFYUI_MANAGER_SKIP_LOAD: "true"
    volumes:
    - ./data/models:/home/appuser/ComfyUI/models
    - ./data/custom_nodes:/home/appuser/ComfyUI/custom_nodes
    - ./data/user:/home/appuser/ComfyUI/user
    - ./data/input:/home/appuser/ComfyUI/input
    - ./data/output:/home/appuser/ComfyUI/output
    - ./data/site-packages:/home/appuser/site-packages
    command:
    - python3
    - main.py
    - --enable-cors-header
    - --disable-smart-memory
    - --listen=0.0.0.0
    - --port=8188
    #- --disable-manager-auto-update
    #- --no-manager
    #- --lowvram
