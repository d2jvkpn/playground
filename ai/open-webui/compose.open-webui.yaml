services:
  open-webui:
    container_name: open-webui
    hostname: open-webui
    image: ghcr.io/open-webui/open-webui:0.5.20
    # image: ghcr.io/open-webui/open-webui:0.6
    depends_on: [ollama]
    extra_hosts:
    - host.docker.internal:host-gateway
    #networks: [net]
    network_mode: bridge
    ports: ["127.0.0.1:3000:3000"]
    environment:
      PORT: 3000 # default=8080
      CORS_ALLOW_ORIGIN: "*"
      ENABLE_OPENAI_API: "false"
      OLLAMA_BASE_URL: http://ollama:11434
      #HF_ENDPOINT: https://hf-mirror.com
      # /app/backend/data/cache/embedding/models/models--sentence-transformers--all-MiniLM-L6-v2/
      RAG_EMBEDDING_MODEL_AUTO_UPDATE: "false"
      #?RAG_RERANKING_MODEL_AUTO_UPDATE: "false"
      #?WHISPER_MODEL_AUTO_UPDATE: "false"
      #QDRANT_URL=http://localhost:6333
      #QDRANT_API_KEY=  # 如果你启用了认证
      #QDRANT_COLLECTION_NAME=open-webui
      #EMBEDDING_MODEL=nomic-embed-text
    volumes:
    - ./data/open-webui:/app/backend/data

  open-webui:
    container_name: open-webui
    hostname: open-webui
    image: ghcr.io/open-webui/open-webui:0.5.20-cuda
    deploy:
      resources:
        reservations:
          # cpus: "1"
          # memory: 4g
          devices:
          - driver: nvidia
            # device_ids: ['0', '3']
            # count: all
            count: 1
            capabilities: [gpu]
    depends_on: [ollama]
    networks: [net]
    extra_hosts:
    - host.docker.internal:host-gateway
    ports: ["127.0.0.1:3000:3000"]
    environment:
      PORT: 3000 # default=8080
      CORS_ALLOW_ORIGIN: "*"
      ENABLE_OPENAI_API: "false"
      OLLAMA_BASE_URL: http://ollama:11434
      #HF_ENDPOINT: https://hf-mirror.com
      # /app/backend/data/cache/embedding/models/models--sentence-transformers--all-MiniLM-L6-v2/
      RAG_EMBEDDING_MODEL_AUTO_UPDATE: "false"
      #?RAG_RERANKING_MODEL_AUTO_UPDATE: "false"
      #?WHISPER_MODEL_AUTO_UPDATE: "false"
      #QDRANT_URL=http://localhost:6333
      #QDRANT_API_KEY=  # 如果你启用了认证
      #QDRANT_COLLECTION_NAME=open-webui
      #EMBEDDING_MODEL=nomic-embed-text
    volumes:
    - ./data/open-webui:/app/backend/data

  # Open WebUI:
  #   Admin Panel ->
  #   Settings ->
  #   Connections ->
  #   OpenAI API ->
  #   Add Connection(+): URL="http://pipelines:9099", Key="0p3n-w3bu!" ->
  #   Pipelines
  pipelines:
    container_name: pipelines
    image: ghcr.io/open-webui/pipelines:main
    depends_on: [open-webui]
    extra_hosts:
      host.docker.internal: host-gateway
    #networks: [net]
    network_mode: bridge
    #ports: ["127.0.0.1:9099:9099"]
    #environment:
    #  PIPELINES_URLS: https://github.com/open-webui/pipelines/blob/main/examples/filters/detoxify_filter_pipeline.py
    volumes:
    - ./data/pipelines:/app/pipelines
